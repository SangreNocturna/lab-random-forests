{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "+ Apply the Random Forests algorithm but this time only by upscaling the data.\n",
    "+ Use Feature Selections that you have learned in class to decide if you want to use all of the features (PCA, etc)\n",
    "+ Discuss the output and its impact in the bussiness scenario. Is the cost of a false positive equals to the cost of the false negative? How would you change your algorithm or data in order to maximize the return of the bussiness?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = pd.read_csv('numerical.csv')\n",
    "categorical = pd.read_csv('categorical.csv')\n",
    "target = pd.read_csv('target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE           object\n",
       "CLUSTER          int64\n",
       "HOMEOWNR        object\n",
       "GENDER          object\n",
       "DATASRCE         int64\n",
       "RFA_2R          object\n",
       "RFA_2A          object\n",
       "GEOCODE2        object\n",
       "DOMAIN_A        object\n",
       "DOMAIN_B         int64\n",
       "ODATEW_YR        int64\n",
       "ODATEW_MM        int64\n",
       "DOB_YR           int64\n",
       "DOB_MM           int64\n",
       "MINRDATE_YR      int64\n",
       "MINRDATE_MM      int64\n",
       "MAXRDATE_YR      int64\n",
       "MAXRDATE_MM      int64\n",
       "LASTDATE_YR      int64\n",
       "LASTDATE_MM      int64\n",
       "FIRSTDATE_YR     int64\n",
       "FIRSTDATE_MM     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = categorical.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE           object\n",
       "CLUSTER         object\n",
       "HOMEOWNR        object\n",
       "GENDER          object\n",
       "DATASRCE        object\n",
       "RFA_2R          object\n",
       "RFA_2A          object\n",
       "GEOCODE2        object\n",
       "DOMAIN_A        object\n",
       "DOMAIN_B        object\n",
       "ODATEW_YR       object\n",
       "ODATEW_MM       object\n",
       "DOB_YR          object\n",
       "DOB_MM          object\n",
       "MINRDATE_YR     object\n",
       "MINRDATE_MM     object\n",
       "MAXRDATE_YR     object\n",
       "MAXRDATE_MM     object\n",
       "LASTDATE_YR     object\n",
       "LASTDATE_MM     object\n",
       "FIRSTDATE_YR    object\n",
       "FIRSTDATE_MM    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95412, 315), (95412, 22), (95412, 2))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical.shape, categorical.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([numerical,categorical], axis = 1)\n",
    "Y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 337)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y['TARGET_B'], test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train.select_dtypes(np.number)\n",
    "X_train_cat = X_train.select_dtypes(object)\n",
    "\n",
    "X_test_num = X_test.select_dtypes(np.number)\n",
    "X_test_cat = X_test.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def EscaladorMinMax(data, MinMaxtransformer):\n",
    "    X_normalized = MinMaxtransformer.transform(data)\n",
    "    print(X_normalized.shape)\n",
    "    X_normalized = pd.DataFrame(X_normalized,columns=data.columns)\n",
    "    return X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinMaxtransformer = MinMaxScaler().fit(X_train_num) # Only run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76329, 315)\n",
      "(19083, 315)\n"
     ]
    }
   ],
   "source": [
    "X_train_num_scaled = EscaladorMinMax(X_train_num, MinMaxtransformer)\n",
    "X_test_num_scaled = EscaladorMinMax(X_test_num, MinMaxtransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCODE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MALEMILI</th>\n",
       "      <th>MALEVET</th>\n",
       "      <th>VIETVETS</th>\n",
       "      <th>WWIIVETS</th>\n",
       "      <th>LOCALGOV</th>\n",
       "      <th>...</th>\n",
       "      <th>CARDGIFT</th>\n",
       "      <th>MINRAMNT</th>\n",
       "      <th>MAXRAMNT</th>\n",
       "      <th>LASTGIFT</th>\n",
       "      <th>TIMELAG</th>\n",
       "      <th>AVGGIFT</th>\n",
       "      <th>CONTROLN</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>CLUSTER2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.422680</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007035</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.019301</td>\n",
       "      <td>0.011970</td>\n",
       "      <td>0.250609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>0.098651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.704918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007035</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>0.476022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.027145</td>\n",
       "      <td>0.790496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.624862</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.020101</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.046939</td>\n",
       "      <td>0.309990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TCODE       AGE    INCOME   WEALTH1       HIT  MALEMILI   MALEVET  \\\n",
       "0  0.000014  0.422680  0.666667  0.888889  0.004149  0.020202  0.181818   \n",
       "1  0.000000  0.624862  0.666667  1.000000  0.000000  0.000000  0.232323   \n",
       "2  0.000014  0.608247  0.166667  1.000000  0.049793  0.000000  0.212121   \n",
       "3  0.000014  0.319588  0.333333  1.000000  0.000000  0.040404  0.414141   \n",
       "4  0.000014  0.624862  0.166667  0.222222  0.000000  0.000000  0.272727   \n",
       "\n",
       "   VIETVETS  WWIIVETS  LOCALGOV  ...  CARDGIFT  MINRAMNT  MAXRAMNT  LASTGIFT  \\\n",
       "0  0.494949  0.070707  0.030303  ...  0.146341     0.006  0.007035     0.011   \n",
       "1  0.292929  0.373737  0.050505  ...  0.000000     0.004  0.005025     0.010   \n",
       "2  0.585859  0.000000  0.070707  ...  0.243902     0.006  0.007035     0.012   \n",
       "3  0.494949  0.252525  0.101010  ...  0.024390     0.030  0.010050     0.015   \n",
       "4  0.474747  0.191919  0.020202  ...  0.024390     0.050  0.020101     0.025   \n",
       "\n",
       "    TIMELAG   AVGGIFT  CONTROLN  HPHONE_D    RFA_2F  CLUSTER2  \n",
       "0  0.019301  0.011970  0.250609       0.0  0.000000  0.262295  \n",
       "1  0.005515  0.012960  0.098651       1.0  0.666667  0.704918  \n",
       "2  0.001838  0.010591  0.476022       0.0  0.333333  0.065574  \n",
       "3  0.008272  0.027145  0.790496       0.0  0.000000  0.131148  \n",
       "4  0.008272  0.046939  0.309990       1.0  0.000000  0.704918  \n",
       "\n",
       "[5 rows x 315 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def OneHotEncoding(data, OneHotEncoder):\n",
    "    encoded = OneHotEncoder.transform(data).toarray()\n",
    "    onehot_encoded = pd.DataFrame(encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop='first', handle_unknown='ignore').fit(X_train_cat) # Only run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat_encoded = OneHotEncoding(X_train_cat, encoder)\n",
    "X_test_cat_encoded = OneHotEncoding(X_test_cat, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  304  305  306  307  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   308  309  310  311  312  313  \n",
       "0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 314 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76329, 315), (76329, 314))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_scaled.shape, X_train_cat_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full train and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.concat([X_train_num_scaled, X_train_cat_encoded], axis = 1)\n",
    "X_test_full = pd.concat([X_test_num_scaled, X_test_cat_encoded], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76329, 629), (19083, 629), (95412, 2))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, X_test_full.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72464\n",
       "1     3865\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding out how many people donated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_0 = trainset[trainset['TARGET_B']== 0 ]\n",
    "category_1 = trainset[trainset['TARGET_B']== 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3865, 338)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upscaling the data from 3865 to 72464"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "category_1_oversampled = resample(category_1, \n",
    "                                replace=True, \n",
    "                                n_samples = len(category_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72464, 338)\n",
      "(72464, 338)\n"
     ]
    }
   ],
   "source": [
    "print(category_0.shape)\n",
    "print(category_1_oversampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_0 = trainset[trainset['TARGET_B']==0].sample(len(trainset[trainset['TARGET_B']==1]))\n",
    "category_1 = trainset[trainset['TARGET_B']== 1 ]\n",
    "trainset_new = pd.concat([category_0, category_1], axis = 0)\n",
    "trainset_new = trainset_new.sample(frac =1) #randomize the rows\n",
    "X_train = trainset_new.drop(['TARGET_B'], axis=1)\n",
    "y_train = trainset_new['TARGET_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'NC'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\JT\\OneDrive - UNIR\\Certificaciones\\IronHack\\IH-Labs\\Week7\\lab-random-forests\\files_for_lab\\lab-random-forest.ipynb Celda 40\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JT/OneDrive%20-%20UNIR/Certificaciones/IronHack/IH-Labs/Week7/lab-random-forests/files_for_lab/lab-random-forest.ipynb#Y104sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JT/OneDrive%20-%20UNIR/Certificaciones/IronHack/IH-Labs/Week7/lab-random-forests/files_for_lab/lab-random-forest.ipynb#Y104sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m clf \u001b[39m=\u001b[39m RandomForestClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,   \u001b[39m# max number of questions to ask\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JT/OneDrive%20-%20UNIR/Certificaciones/IronHack/IH-Labs/Week7/lab-random-forests/files_for_lab/lab-random-forest.ipynb#Y104sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                             min_samples_split\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,   \u001b[39m# amount of rows still considered at every question\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JT/OneDrive%20-%20UNIR/Certificaciones/IronHack/IH-Labs/Week7/lab-random-forests/files_for_lab/lab-random-forest.ipynb#Y104sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                             min_samples_leaf \u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,   \u001b[39m# ultimate answer based on at least this many rows\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JT/OneDrive%20-%20UNIR/Certificaciones/IronHack/IH-Labs/Week7/lab-random-forests/files_for_lab/lab-random-forest.ipynb#Y104sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                             max_samples\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m,    \u001b[39m# fraction of X-train to use in each tree\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/JT/OneDrive%20-%20UNIR/Certificaciones/IronHack/IH-Labs/Week7/lab-random-forests/files_for_lab/lab-random-forest.ipynb#Y104sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                             random_state \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/JT/OneDrive%20-%20UNIR/Certificaciones/IronHack/IH-Labs/Week7/lab-random-forests/files_for_lab/lab-random-forest.ipynb#Y104sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JT/OneDrive%20-%20UNIR/Certificaciones/IronHack/IH-Labs/Week7/lab-random-forests/files_for_lab/lab-random-forest.ipynb#Y104sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(clf\u001b[39m.\u001b[39mscore(X_train, y_train))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/JT/OneDrive%20-%20UNIR/Certificaciones/IronHack/IH-Labs/Week7/lab-random-forests/files_for_lab/lab-random-forest.ipynb#Y104sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(clf\u001b[39m.\u001b[39mscore(X_test, y_test))\n",
      "File \u001b[1;32mc:\\Users\\JT\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:331\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 331\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    332\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    333\u001b[0m )\n\u001b[0;32m    334\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\JT\\anaconda3\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\JT\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1070\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1066\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1067\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1068\u001b[0m     )\n\u001b[1;32m-> 1070\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1071\u001b[0m     X,\n\u001b[0;32m   1072\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1073\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1074\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1075\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1076\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1077\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1078\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1079\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1080\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1081\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1082\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1083\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1084\u001b[0m )\n\u001b[0;32m   1086\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1088\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\JT\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:852\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    850\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    851\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 852\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    853\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    854\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    855\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    856\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JT\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2069\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2069\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'NC'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=5,   # max number of questions to ask\n",
    "                            min_samples_split=20,   # amount of rows still considered at every question\n",
    "                            min_samples_leaf =20,   # ultimate answer based on at least this many rows\n",
    "                            max_samples=0.8,    # fraction of X-train to use in each tree\n",
    "                            random_state = 42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "display(y_test.value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6df17fb4df13b71ec05b4aa94d3608f0ccf4cd310a274d15d56bf76c7ef9733e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
